@page "/chatgptchat1"
@using System.Net.Http.Headers
@using System.Text.Json
@rendermode InteractiveServer
@inject IConfiguration Configuration


<RadzenStack class="rz-p-0 rz-p-md-12">
    <RadzenCard Class="rz-p-4" Variant="Variant.Outlined">
        <RadzenStack Orientation="Orientation.Vertical" Gap="0.5rem">
            <RadzenLabel Text="ChatGPT Chat"/>
        </RadzenStack>
    </RadzenCard>

    <!-- Radzen AI Chat -->
    <RadzenAIChat @ref="_chat"
                  Title="AI Assistant"
                  Placeholder="Ask me anything..."
                  Style="height: 500px;"
                  MessageSent="OnMessageSent"
                  ResponseReceived="OnResponseReceived"
                  ChatCleared="OnChatCleared"/>
</RadzenStack>

@code {
    RadzenAIChat? _chat;

    private string? _apiKey;
    private const string Endpoint = "https://api.openai.com/v1/responses";

    private readonly HttpClient _httpClient = new()
    {
        BaseAddress = new Uri("https://api.openai.com/")
    };


    protected override void OnInitialized()
    {
        //TODO see how to remove from here

        _apiKey = Environment.GetEnvironmentVariable("OpenApiKey") ??
                  Configuration["OpenApiKey"] ??
                  throw new InvalidOperationException("OpenApiKey configuration is missing");

        _httpClient.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue("Bearer", _apiKey);
    }

    async Task OnMessageSent(string userMessage)
    {
        System.Console.WriteLine($"Message sent: {userMessage}", AlertStyle.Info);

        // Send to OpenAI
        var (response, promptTokens, completionTokens) = await GetCompletion(userMessage);

        if (!string.IsNullOrEmpty(response))
        {
            // Combine AI response with tokens info
            var fullResponse = $"{response}\n\n---\n_Tokens used — Prompt: {promptTokens}, Completion: {completionTokens}_";

            // Add assistant response with inline tokens
            _chat!.AddMessage(fullResponse, false);
        }

        StateHasChanged();
    }


    void OnResponseReceived(string response)
    {
        Console.WriteLine($"AI Response: {response.Substring(0, Math.Min(50, response.Length))}...", AlertStyle.Success);
    }

    void OnChatCleared()
    {
        Console.WriteLine("Chat cleared", AlertStyle.Warning);
    }

    private async Task<(string? content, int promptTokens, int completionTokens)> GetCompletion(string prompt)
    {
        var data = new
        {
            model = "gpt-4.1-nano",
            input = prompt, // ✅ use input instead of messages
            temperature = 0.7
        };

        var jsonString = JsonSerializer.Serialize(data);
        var content = new StringContent(jsonString, Encoding.UTF8, "application/json");

        var response = await _httpClient.PostAsync("v1/responses", content);
        if (!response.IsSuccessStatusCode)
        {
            var errorContent = await response.Content.ReadAsStringAsync();
            throw new HttpRequestException($"OpenAI API request failed with status {response.StatusCode}: {errorContent}");
        }

        var responseContent = await response.Content.ReadAsStringAsync();

        using JsonDocument doc = JsonDocument.Parse(responseContent);
        JsonElement root = doc.RootElement;

        // ✅ Responses API has different usage field names
        var promptTokens = root.GetProperty("usage").GetProperty("prompt_tokens").GetInt32();
        var completionTokens = root.GetProperty("usage").GetProperty("completion_tokens").GetInt32();

        // ✅ Different response shape: "output_text" is the merged string output
        var messageContent = root.GetProperty("output_text").GetString();

        return (messageContent, promptTokens, completionTokens);
    }

}


